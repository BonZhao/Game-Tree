%Directional part
\chapter{Analysis of Directional Algorithm}
In this chapter, we will analyze the process of deterministic directional algorithm for nor-tree evaluation. With computing the lower bound of this algorithm, we will compare its difference with general evaluation process.
%\label{ch:bg}

\section{Directional Algorithm}
We begin by analyzing a class of directional algorithms' lower bounds, as per the following definition.
	\begin{definition}
	\label{def:directional}
	A {\em deterministic directional algorithm\/} 
	for a NOR tree $T$ is the leaf sequence in the order visited by
	a depth-first traversal of $T$
	except that it omits the visit of a child of a vertex $u$
	if $u$'s value has already been determined.
	A {\em randomized directional algorithm\/}
	is a probability distribution over deterministic directional algorithms.
   \end{definition}

We claim that any randomized directional algorithm must visit  
$L(k,1)$ leaves, where $L(k,1)$ will be defined shortly.
The proof relies on Yao's principle,
whereby it is sufficient to show a probability distribution on
the leaf labels that forces any deterministic directional algorithm
to visit $L(k,1)$ leaves in the expectation.
The probability distribution is built recursively for a tree of height
$k$ from the probability distribution of trees of height $k-1$.
The distribution assigns labels in such a way that a tree 
of height $k$ always evaluates to true. 
Therefore, both root sub-trees of height $k-1$ evaluate to false.
In turn, if a sub-tree must evaluate to false, then
leaf values will be assigned in such a way that
one of the sub-trees evaluates to true and the other to false,
and the two alternatives are chosen with probability $1/2$.
Such a probability distribution on leaf labels will be termed a 
{\em reluctant input\/}.

Let $L(k, i)$ ($k = 0, 1, 2, \dots$; $i = 0 ,1$) be 
the expected number of leaves visited by a deterministic
depth-first pruned algorithm in correspondence to a 
reluctant input for a tree of height $k$ which evaluates
to true  or false if $i = 1$ or $0$ respectively.

Then the recurrence relationship is:
\begin{flalign}
\label{eqn:L1} L(k, 1) &= 2L(k-1, 0)\\
\label{eqn:L0} L(k,0) &= L(k-1, 1)+\frac{1}{2}L(k-1, 0)\\
\label{eqn:Lbase} L(0,i) &= 1 \quad (i = 0, 1)
\end{flalign}

\section{Lower Bound Analysis}
In this section, we will show that $L(k, 0) \ge \rho_{k+1} a^{k+1} / 2$,
where $a = (1 + \sqrt{33}) / 4 \approx 1.6861$, and 
$\lim_{k \rightarrow \infty} \rho_k \approx 1.10927$.
Then, by \eqref{eqn:L1}, we have that 
\begin{equation}
\label{eqn:L1bound}
L(k, 1) = 2 L(k-1, 0) \ge \rho_{k+1} a^k
\end{equation}

First of all, we could get the initial condition by calculation:
\begin{flalign} 
\label{eqn:ini0} L(1,0) = 1\\
\label{eqn:ini1} L(1,1) = 2\\
\label{eqn:ini2} L(2,1) = 3
\end{flalign}

Define the sequence $\rho_k$ as the solution to the recurrence in previous section for $L(k,0)$, with the initial condition above and \eqref{eqn:L1}:
\begin{flalign}
\label{eq:rhokrecursive} \rho_k &=  \frac{\rho_{k-1}}{2 a} + 2 \frac{\rho_{k-2}}{a^2}\\
\label{eq:rhok2}         \rho_2 &= \frac{3}{a^2}\\
\label{eq:rhok1}         \rho_1 &= \frac{2}{a}
\end{flalign}

Then we claim that:
\begin{lemma}
	\label{lemma:rhok}
	We have that 
	$$\lim_{k \rightarrow \infty} \rho_k = \rho = 
	\frac{20 \sqrt{2} + 4 \sqrt{66}}{\sqrt{66} + 33 \sqrt{2}}
	\approx 1.10927\;.$$
\end{lemma}

\begin{proof}
	Define
	\begin{alignat*}{2}
	\vect{r}_{k-1} & = 
	\begin{pmatrix}
	\rho_k \\
	\rho_{k-1}
	\end{pmatrix} &\qquad&
	(k = 2, \dots )
	\end{alignat*}
	In extended state representation, 
	recurrence \eqref{eq:rhokrecursive}-\eqref{eq:rhok1}
	becomes $\vect{r}_k = A \vect{r}_{k-1}$, where
	$$A = 
	\begin{pmatrix}
	\frac{1}{2 a} & \frac{2}{a^2} \\
	1             & 0 
	\end{pmatrix}\;.$$
	It is immediate to see
	that the eigenvalues of $A$ are $\lambda_1 = 1$ and 
	$\lambda_2 = (1 - \sqrt{33}) / (1 + \sqrt{33})$, and that
	$-1 < \lambda_2 < 0$.
	Therefore, $\vect{r}_k$ tends to the projection of $\vect{r}_1$ along an eigenvector 
	$\vect{v}_1$ corresponding to $\lambda_1$.
	Furthermore,
	it can be verified that a unit eigenvector corresponding to $\lambda_1$ ($\lambda_2$) is:
	
	\begin{alignat*}{2}
	\vect{v}_1 & = 
	\frac{\sqrt{2}}{2}
	\begin{pmatrix}
	1\\
	1
	\end{pmatrix} 
	& \qquad &
	\left(
	\vect{v}_2 = 
	\frac{1}{\sqrt{\lambda_2^2+1}}
	\begin{pmatrix}
	\lambda_2\\
	1
	\end{pmatrix}
	\right)
	\end{alignat*}
	
	The component $r$ of $\vect{r}_1$ along $\vect{v}_1$ is given by solving 
	$$\begin{pmatrix}
	\vect{v}_1 & \vect{v}_2   
	\end{pmatrix} 
	\begin{pmatrix}
	r\\
	s   
	\end{pmatrix} = 
	\begin{pmatrix}
	\rho_2\\
	\rho_1
	\end{pmatrix}
	$$
	and is equal to
	$r = (40 + 8 \sqrt{33})/(\sqrt{66} + 33 \sqrt{2})$.
	Since $\lim_{k\rightarrow \infty} \vect{r}_k = r \vect{v}_1$, 
	by definition of $\vect{r}_k$ and $\vect{v}_1$ we have that
	$$\lim_{k\rightarrow \infty} \rho_k = \frac{\sqrt{2}}{2} r = 
	\frac{20 \sqrt{2} + 4 \sqrt{66}}{\sqrt{66} + 33 \sqrt{2}}\;,$$
	which proves the claim.
\end{proof}

As we have $\rho_{k}$ as constant when $k$ goes to infinity. We could claim:
\begin{lemma}
	$L(k, 0)$ is bounded by $L(k, 0) = \rho_{k+1} a^{k+1} / 2$.
\end{lemma}

\begin{proof}
	Define for convenience of notation $T(k) = L(k, 0)$.
	By \eqref{eqn:Lbase} and \eqref{eq:rhok1}, 
	we have that $T(0) = \rho_1 a / 2$.
	Furthermore, by \eqref{eqn:L0}, \eqref{eqn:Lbase}, and \eqref{eq:rhok2},
	we have that $T(1) = 3 /2 = \rho_2 a^2 / 2$.
	Substitute \eqref{eqn:L1} in \eqref{eqn:L0} to obtain:
	$T(k) = 2 T(k-2) + T(k-1) / 2$.
	By induction hypothesis and definition \eqref{eq:rhokrecursive},
	$T(k) = \rho_{k-1} a^{k-1} + \rho_k a^k / 4 
	= a^{k-1} \left( \rho_{k-1} + \rho_k a / 4 \right)
	= \rho_{k+1} a^{k+1} / 2$,
	which completes the proof.
\end{proof}

  Therefore, by combining $lemma 2$ and  \eqref{eqn:L1}, we could obtain the following tighter lower bound:
  
  \begin{theorem}
  	We have that 
  	$\lim_{k \rightarrow \infty} L(k, 0) / a^{k+1} = \rho / 2$
  	and
  	$\lim_{k \rightarrow \infty} L(k, 1) / a^k = \rho$.
  \end{theorem}

\section{Comparison}

The difference between the lower bound discussed in this thesis and the one in 'Randomized Algorithms' ~\cite{MR} is shown in the table below:

\begin{tabular}{ |p{3cm}||p{5cm}|p{5cm}|  }
	\hline
	\multicolumn{3}{|c|}{Comparison} \\
	\hline
	Item & This article & 'Randomized Algorithms'\\
	\hline
	root   & r=1    & r= 0 with probability 1-p or 1 with probability p\\
	\hline
	Lower Bound&   $L(k,1)\ge\rho_{k+1}\alpha^k$  & $pL(k,1)+(1-p)L(k,0)\ge p\rho_{k+1}\alpha^k+(1-p)\rho_{k+1}(L_0)\frac{\alpha^{k+1}}{2}$\\
	\hline
\end{tabular}
\newline
The Lower bound in 'Randomized Algorithms' equals to:
$$\rho_{k+1}\alpha^k[p+(1-p)\frac{\alpha}{2}]=L_0[p+(1-p)\frac{\alpha}{2}]\ge L(k,1)$$
with $\alpha=\frac{1+\sqrt{33}}{4}, p=\frac{3-\sqrt{5}}{2}$

With Calculation(Appendix: Detailed Calculation), we could see that the lower bound in this article is better than the previous one. 